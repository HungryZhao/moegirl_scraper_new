import time
import scrapy
from moegirl.items import CategoryItem, ArticleItem
from urllib.parse import urlparse, parse_qs

class MoegirlSpider(scrapy.Spider):
    name = 'moegirl'
    allowed_domains = ['moegirl.icu']
    start_urls = ['https://moegirl.icu/index.php?title=Category:ä½œå“']

    custom_settings = {
        # ä½¿ç”¨ scrapy-playwright è¿›è¡Œæ¸²æŸ“ï¼Œç»•è¿‡ Cloudflare
        'DOWNLOAD_HANDLERS': {
            'http': 'scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler',
            'https': 'scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler',
        },
        'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
        'PLAYWRIGHT_BROWSER_TYPE': 'chromium',  # å¯é€‰ 'firefox' æˆ– 'webkit'
        'PLAYWRIGHT_LAUNCH_OPTIONS': {'headless': True},
        'CONCURRENT_REQUESTS': 5,
    }

    def start_requests(self):
        self.logger.info("ğŸ”” å»¶è¿Ÿ 60 ç§’åå†å¼€å§‹çˆ¬å–â€¦")
        time.sleep(60)
        # æ‰€æœ‰è¯·æ±‚éƒ½å¯ç”¨ Playwright
        for url in self.start_urls:
            yield scrapy.Request(url, meta={'playwright': True}, callback=self.parse)

    def parse(self, response):
        # ä»æ ¹åˆ†ç±»å¼€å§‹è§£æ
        yield from self.parse_category(response, parent=None)

    def parse_category(self, response, parent):
        title = response.css('title::text').get().split(' - ')[0]
        category = CategoryItem(
            name=title,
            parent_categories=[parent] if parent else [],
            subcategories=[]
        )

        # è§£æå­åˆ†ç±»
        for a in response.css('#mw-subcategories .mw-content-ltr a'):
            name = a.css('::text').get()
            url = response.urljoin(a.attrib['href'])
            category['subcategories'].append(name)
            yield scrapy.Request(url,
                                  meta={'playwright': True},
                                  callback=self.parse_category,
                                  cb_kwargs={'parent': title})

        # è§£æè¯æ¡åˆ—è¡¨
        for a in response.css('#mw-pages .mw-content-ltr a'):
            href = a.attrib['href']
            raw_url = response.urljoin(href) + '&action=raw'
            yield scrapy.Request(raw_url,
                                  meta={'playwright': True},
                                  callback=self.parse_article,
                                  cb_kwargs={'categories': [title]})

        # ç¿»é¡µï¼šå­åˆ†ç±»
        next_sub = response.xpath("//div[@id='mw-subcategories']//a[text()='ä¸‹ä¸€é¡µ']/@href").get()
        if next_sub:
            yield response.follow(next_sub,
                                  meta={'playwright': True},
                                  callback=self.parse_category,
                                  cb_kwargs={'parent': parent})
        # ç¿»é¡µï¼šè¯æ¡åˆ—è¡¨
        next_page = response.xpath("//div[@id='mw-pages']//a[text()='ä¸‹ä¸€é¡µ']/@href").get()
        if next_page:
            yield response.follow(next_page,
                                  meta={'playwright': True},
                                  callback=self.parse_category,
                                  cb_kwargs={'parent': parent})

        yield category

    def parse_article(self, response, categories):
        qs = urlparse(response.url).query
        title = parse_qs(qs).get('title', [''])[0]
        yield ArticleItem(
            title=title,
            content=response.text,
            categories=categories
        )